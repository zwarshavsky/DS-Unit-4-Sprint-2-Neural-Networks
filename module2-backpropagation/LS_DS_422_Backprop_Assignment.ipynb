{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NGGrt9EYlCqY"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Backpropagation Practice\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 2*\n",
    "\n",
    "Implement a 3 input, 4 node hidden-layer, 1 output node Multilayer Perceptron on the following dataset:\n",
    "\n",
    "| x1 | x2 | x3 | y |\n",
    "|----|----|----|---|\n",
    "| 0  | 0  | 1  | 0 |\n",
    "| 0  | 1  | 1  | 1 |\n",
    "| 1  | 0  | 1  | 1 |\n",
    "| 0  | 1  | 0  | 1 |\n",
    "| 1  | 0  | 0  | 1 |\n",
    "| 1  | 1  | 1  | 0 |\n",
    "| 0  | 0  | 0  | 0 |\n",
    "\n",
    "If you look at the data you'll notice that the first two columns behave like an XOR gate while the last column is mostly just noise. Remember that creating an XOR gate was what the perceptron was criticized for not being able to learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nEREYT-3wI1f"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "data = { 'x1': [0,0,1,0,1,1,0],\n",
    "         'x2': [0,1,0,1,0,1,0],\n",
    "         'x3': [1,1,1,0,0,1,0],\n",
    "         'y':  [0,1,1,1,1,0,0]\n",
    "       }\n",
    "\n",
    "df = pd.DataFrame.from_dict(data).astype('int')\n",
    "\n",
    "inputs = df[[\"x1\",\"x2\",\"x3\"]]\n",
    "correct_output = df[[\"y\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [-2],\n",
       "       [ 1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_sum = perceptron_nand_gate()\n",
    "weighted_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simplePerceptron:\n",
    "    def __init__(self):\n",
    "        self.inputs = 3\n",
    "        self.hidden = 4 \n",
    "        self.output = 1\n",
    "        \n",
    "        self.weights = np.random.rand(self.inputs, self.hidden)\n",
    "        # weights in shape of 3 x 4 \n",
    "        self.weights2 = np.random.rand(self.hidden, self.output)\n",
    "        \n",
    "    def sigmoid(self, s):\n",
    "        return 1 / (1 + np.exp(-s))\n",
    "    \n",
    "    def sigmoid_derivative(self, s):\n",
    "        return s * (1 - s)\n",
    "    \n",
    "    def feed_forward(self, X):\n",
    "        \"\"\"Perform steps 2 - 5\"\"\"\n",
    "        self.first_weighted_sum = np.dot(X, self.weights)\n",
    "        \n",
    "        self.activated_hidden = self.sigmoid(self.first_weighted_sum)\n",
    "        \n",
    "        self.second_weighted_sum = np.dot(self.activated_hidden, self.weights2)\n",
    "        \n",
    "        self.activated_output = self.sigmoid(self.second_weighted_sum)\n",
    "        \n",
    "        return self.activated_output\n",
    "    \n",
    "    def back_propogate(self, X, y):\n",
    "        \"\"\"Backpropogate\"\"\"\n",
    "        # Computing error; difference of actual and predicted \n",
    "        self.error_output = y - self.activated_output\n",
    "        \n",
    "        self.delta_output = self.error_output * self.sigmoid_derivative(self.activated_output)\n",
    "        \n",
    "        self.error_hidden = np.dot(self.delta_output, self.weights2.T)\n",
    "        \n",
    "        self.delta_hidden = self.error_hidden * self.sigmoid_derivative(self.activated_hidden)\n",
    "        \n",
    "        # Adjustments to weights and weights2\n",
    "        self.weights += np.dot(X.T, self.delta_hidden)\n",
    "        self.weights2 += np.dot(self.activated_hidden.T, self.delta_output)\n",
    "        \n",
    "        return True \n",
    "        \n",
    "    def train(self, X, y, iter=10000):\n",
    "        #Always good idea to return something even if you don't have to\n",
    "        for epoch in range(iter):\n",
    "            self.feed_forward(X)\n",
    "            self.back_propogate(X, y)\n",
    "        return self.__dict__\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return [1 if prediction > 0.5 else 0 for prediction in self.feed_forward(X)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"x1\",\"x2\",\"x3\"]]\n",
    "y = df[[\"y\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron = simplePerceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputs': 3,\n",
       " 'hidden': 4,\n",
       " 'output': 1,\n",
       " 'weights': array([[-3.94876085,  6.89165957, -2.00175882,  5.53523316],\n",
       "        [ 6.9315279 , -4.15430185, -1.70828415,  5.50818065],\n",
       "        [ 0.79765283,  1.09331662, -1.51839369,  0.12412393]]),\n",
       " 'weights2': array([[-9.77068103],\n",
       "        [-9.87486689],\n",
       "        [-3.60622245],\n",
       "        [15.0009424 ]]),\n",
       " 'first_weighted_sum': array([[ 0.79764787,  1.0933149 , -1.5183748 ,  0.12411786],\n",
       "        [ 7.72913472, -3.06096788, -3.22659092,  5.63228575],\n",
       "        [-3.15109257,  7.98493501, -3.52007848,  5.65933815],\n",
       "        [ 6.93148685, -4.15428278, -1.70821613,  5.50816789],\n",
       "        [-3.94874044,  6.89162011, -2.00170368,  5.53522029],\n",
       "        [ 3.78039428,  3.83065223, -5.22829461, 11.16750604],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ]]),\n",
       " 'activated_hidden': array([[0.68947111, 0.74900543, 0.17970096, 0.53098969],\n",
       "        [0.99956037, 0.04474631, 0.03817723, 0.99643239],\n",
       "        [0.04104825, 0.99965956, 0.0287463 , 0.99652728],\n",
       "        [0.9990244 , 0.01545446, 0.15339524, 0.99596284],\n",
       "        [0.01891432, 0.99898477, 0.11902416, 0.99607017],\n",
       "        [0.97769516, 0.97876524, 0.00533406, 0.99998587],\n",
       "        [0.5       , 0.5       , 0.5       , 0.5       ]]),\n",
       " 'second_weighted_sum': array([[-6.81555497],\n",
       "        [ 4.60146984],\n",
       "        [ 4.57256978],\n",
       "        [ 4.47342156],\n",
       "        [ 4.46308328],\n",
       "        [-4.23638677],\n",
       "        [-4.12534884]]),\n",
       " 'activated_output': array([[0.00109538],\n",
       "        [0.99006267],\n",
       "        [0.98977427],\n",
       "        [0.98872046],\n",
       "        [0.98860458],\n",
       "        [0.01425364],\n",
       "        [0.01590093]]),\n",
       " 'error_output': array([[-0.00109538],\n",
       "        [ 0.00993733],\n",
       "        [ 0.01022573],\n",
       "        [ 0.01127954],\n",
       "        [ 0.01139542],\n",
       "        [-0.01425364],\n",
       "        [-0.01590093]]),\n",
       " 'delta_output': array([[-1.19855022e-06],\n",
       "        [ 9.77692179e-05],\n",
       "        [ 1.03496302e-04],\n",
       "        [ 1.25792855e-04],\n",
       "        [ 1.28375745e-04],\n",
       "        [-2.00270395e-04],\n",
       "        [-2.48819255e-04]]),\n",
       " 'error_hidden': array([[ 1.17105428e-05,  1.18354240e-05,  4.32213753e-06,\n",
       "         -1.79792289e-05],\n",
       "        [-9.55262949e-04, -9.65449868e-04, -3.52569296e-04,\n",
       "          1.46661785e-03],\n",
       "        [-1.01121994e-03, -1.02200359e-03, -3.73221953e-04,\n",
       "          1.55252878e-03],\n",
       "        [-1.22907042e-03, -1.24217722e-03, -4.53626400e-04,\n",
       "          1.88699522e-03],\n",
       "        [-1.25430678e-03, -1.26768270e-03, -4.62940658e-04,\n",
       "          1.92574067e-03],\n",
       "        [ 1.95675993e-03,  1.97762681e-03,  7.22202691e-04,\n",
       "         -3.00421895e-03],\n",
       "        [ 2.43111094e-03,  2.45703629e-03,  8.97276580e-04,\n",
       "         -3.73249136e-03]]),\n",
       " 'delta_hidden': array([[ 2.50723538e-06,  2.22501590e-06,  6.37119928e-07,\n",
       "         -4.47754066e-06],\n",
       "        [-4.19778732e-07, -4.12672675e-05, -1.29462492e-05,\n",
       "          5.21365175e-06],\n",
       "        [-3.98049446e-05, -3.47811114e-07, -1.04203400e-05,\n",
       "          5.37277573e-06],\n",
       "        [-1.19790526e-06, -1.89004913e-05, -5.89102547e-05,\n",
       "          7.58735054e-06],\n",
       "        [-2.32756306e-05, -1.28568836e-06, -4.85427588e-05,\n",
       "          7.53810252e-06],\n",
       "        [ 4.26717157e-05,  4.11026942e-05,  3.83172295e-06,\n",
       "         -4.24358653e-08],\n",
       "        [ 6.07777734e-04,  6.14259073e-04,  2.24319145e-04,\n",
       "         -9.33122840e-04]])}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron.train(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 1, 1, 0, 0]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(T.J)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Cost')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8b-r70o8p2Dm"
   },
   "source": [
    "## Try building/training a more complex MLP on a bigger dataset.\n",
    "\n",
    "Use the [MNIST dataset](http://yann.lecun.com/exdb/mnist/) to build the cannonical handwriting digit recognizer and see what kind of accuracy you can achieve. \n",
    "\n",
    "If you need inspiration, the internet is chalk-full of tutorials, but I want you to see how far you can get on your own first. I've linked to the original MNIST dataset above but it will probably be easier to download data through a neural network library. If you reference outside resources make sure you understand every line of code that you're using from other sources, and share with your fellow students helpful resources that you find.\n",
    "\n",
    "\n",
    "### Parts\n",
    "1. Gathering & Transforming the Data\n",
    "2. Making MNIST a Binary Problem\n",
    "3. Estimating your Neural Network (the part you focus on)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering the Data \n",
    "\n",
    "`keras` has a handy method to pull the mnist dataset for you. You'll notice that each observation is a 28x28 arrary which represents an image. Although most Neural Network frameworks can handle higher dimensional data, that is more overhead than necessary for us. We need to flatten the image to one long row which will be 784 values (28X28). Basically, you will be appending each row to one another to make on really long row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], img_rows * img_cols)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows * img_cols)\n",
    "\n",
    "# Normalize Our Data\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now the data should be in a format you're more familiar with\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making MNIST a Binary Problem \n",
    "MNIST is multiclass classification problem; however we haven't covered all the necessary techniques to handle this yet. You would need to one-hot encode the target, use a different loss metric, and use softmax activations for the last layer. This is all stuff we'll cover later this week, but let us simply the problem for now: Zero or all else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_temp = np.zeros(y_train.shape)\n",
    "y_temp[np.where(y_train == 0.0)[0]] = 1\n",
    "y_train = y_temp\n",
    "\n",
    "y_temp = np.zeros(y_test.shape)\n",
    "y_temp[np.where(y_test == 0.0)[0]] = 1\n",
    "y_test = y_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A Nice Binary target for ya to work with\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use a subsample to below 7K at first\n",
    "\n",
    "### Estimating Your `net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5MOPtYdk1HgA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8507, 18502,  2852, ..., 29921, 40465, 32999])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sample_index = np.random.randint(x_train.shape[0], size=5000)\n",
    "\n",
    "sample_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sample = x_train[sample_index]\n",
    "y_sample = y_train[sample_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sample_df = pd.DataFrame(data=x_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  774  775  776  777  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   778  779  780  781  782  783  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sample_df = pd.DataFrame(data=y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sample_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0  0.0\n",
       "1  0.0\n",
       "2  0.0\n",
       "3  0.0\n",
       "4  0.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x_sample_df.values\n",
    "y = y_sample_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simplePerceptron:\n",
    "    def __init__(self):\n",
    "        self.inputs = 784\n",
    "        self.hidden = 100 \n",
    "        self.output = 1\n",
    "        \n",
    "        self.weights = np.random.rand(self.inputs, self.hidden)\n",
    "        # weights in shape of 784 x 2 \n",
    "        self.weights2 = np.random.rand(self.hidden, self.output)\n",
    "        \n",
    "    def sigmoid(self, s):\n",
    "        return 1 / (1 + np.exp(-s))\n",
    "    \n",
    "    def sigmoid_derivative(self, s):\n",
    "        return s * (1 - s)\n",
    "    \n",
    "    def feed_forward(self, X):\n",
    "        \"\"\"Perform steps 2 - 5\"\"\"\n",
    "        self.first_weighted_sum = np.dot(X, self.weights)\n",
    "        \n",
    "        self.activated_hidden = self.sigmoid(self.first_weighted_sum)\n",
    "        \n",
    "        self.second_weighted_sum = np.dot(self.activated_hidden, self.weights2)\n",
    "        \n",
    "        self.activated_output = self.sigmoid(self.second_weighted_sum)\n",
    "        \n",
    "        return self.activated_output\n",
    "    \n",
    "    def back_propogate(self, X, y):\n",
    "        \"\"\"Backpropogate\"\"\"\n",
    "        # Computing error; difference of actual and predicted \n",
    "        self.error_output = y - self.activated_output\n",
    "        \n",
    "        self.delta_output = self.error_output * self.sigmoid_derivative(self.activated_output)\n",
    "        \n",
    "        self.error_hidden = np.dot(self.delta_output, self.weights2.T)\n",
    "        \n",
    "        self.delta_hidden = self.error_hidden * self.sigmoid_derivative(self.activated_hidden)\n",
    "        \n",
    "        # Adjustments to weights and weights2\n",
    "        self.weights += np.dot(X.T, self.delta_hidden)\n",
    "        self.weights2 += np.dot(self.activated_hidden.T, self.delta_output)\n",
    "        \n",
    "        return True \n",
    "        \n",
    "    def train(self, X, y, iter=1000):\n",
    "        #Always good idea to return something even if you don't have to\n",
    "        for epoch in range(iter):\n",
    "            self.feed_forward(X)\n",
    "            self.back_propogate(X, y)\n",
    "        return self.__dict__\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return [1 if prediction > 0.5 else 0 for prediction in self.feed_forward(X)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron = simplePerceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputs': 784,\n",
       " 'hidden': 100,\n",
       " 'output': 1,\n",
       " 'weights': array([[0.27197744, 0.70762825, 0.93490673, ..., 0.62933368, 0.58255197,\n",
       "         0.79761141],\n",
       "        [0.70282132, 0.77926475, 0.18128999, ..., 0.03108639, 0.65037309,\n",
       "         0.03925115],\n",
       "        [0.798739  , 0.70023785, 0.86025032, ..., 0.32003748, 0.98626702,\n",
       "         0.93096148],\n",
       "        ...,\n",
       "        [0.13858711, 0.70363287, 0.37316954, ..., 0.32120851, 0.06850338,\n",
       "         0.06810358],\n",
       "        [0.97142378, 0.82981612, 0.77855434, ..., 0.57081569, 0.30742918,\n",
       "         0.37475161],\n",
       "        [0.18747148, 0.33935368, 0.92003243, ..., 0.52575283, 0.48612199,\n",
       "         0.27032697]]),\n",
       " 'weights2': array([[2.98885210e-01],\n",
       "        [2.38447185e-01],\n",
       "        [6.86893559e-01],\n",
       "        [7.53289767e-01],\n",
       "        [6.16978070e-01],\n",
       "        [9.33354363e-01],\n",
       "        [5.38499628e-01],\n",
       "        [7.00130014e-01],\n",
       "        [8.61728785e-01],\n",
       "        [1.25334800e-01],\n",
       "        [2.84732884e-01],\n",
       "        [1.17090273e-01],\n",
       "        [8.62630735e-01],\n",
       "        [3.90833927e-01],\n",
       "        [2.94612627e-01],\n",
       "        [1.09814347e-01],\n",
       "        [9.60323133e-01],\n",
       "        [4.79289855e-01],\n",
       "        [8.53292482e-01],\n",
       "        [3.83964530e-01],\n",
       "        [4.17274713e-01],\n",
       "        [6.77328081e-01],\n",
       "        [8.05199326e-01],\n",
       "        [6.64337120e-01],\n",
       "        [8.45273923e-01],\n",
       "        [8.01194710e-01],\n",
       "        [7.57622971e-01],\n",
       "        [3.41191873e-01],\n",
       "        [5.54493903e-01],\n",
       "        [1.08730370e-01],\n",
       "        [5.22908140e-01],\n",
       "        [4.50173674e-01],\n",
       "        [8.97593500e-01],\n",
       "        [4.80478742e-01],\n",
       "        [3.05058776e-01],\n",
       "        [1.95826898e-02],\n",
       "        [5.29827493e-01],\n",
       "        [7.85027485e-01],\n",
       "        [3.24402181e-01],\n",
       "        [4.20638574e-02],\n",
       "        [4.40776775e-01],\n",
       "        [8.55054808e-02],\n",
       "        [8.22215880e-01],\n",
       "        [7.69160121e-01],\n",
       "        [5.69573126e-01],\n",
       "        [6.77348334e-01],\n",
       "        [2.84829421e-01],\n",
       "        [5.30244997e-01],\n",
       "        [6.59494149e-01],\n",
       "        [1.80099680e-01],\n",
       "        [8.44991415e-02],\n",
       "        [5.24324407e-01],\n",
       "        [4.75086841e-01],\n",
       "        [1.56634684e-01],\n",
       "        [5.45933725e-01],\n",
       "        [1.82096817e-01],\n",
       "        [3.21696669e-01],\n",
       "        [6.19339116e-01],\n",
       "        [2.47498571e-02],\n",
       "        [2.37175638e-01],\n",
       "        [8.19986415e-01],\n",
       "        [7.03762709e-01],\n",
       "        [7.53572153e-01],\n",
       "        [8.43380072e-01],\n",
       "        [1.47177261e-05],\n",
       "        [2.53844783e-01],\n",
       "        [7.82385180e-02],\n",
       "        [4.81235487e-01],\n",
       "        [9.16972354e-01],\n",
       "        [5.28716423e-02],\n",
       "        [1.63912375e-01],\n",
       "        [9.87535640e-01],\n",
       "        [1.64624967e-01],\n",
       "        [2.34025973e-01],\n",
       "        [1.61965996e-01],\n",
       "        [2.82709626e-01],\n",
       "        [8.44107899e-01],\n",
       "        [2.73956543e-01],\n",
       "        [8.60293281e-03],\n",
       "        [2.46366947e-01],\n",
       "        [5.17379337e-01],\n",
       "        [8.63075378e-01],\n",
       "        [1.55553076e-01],\n",
       "        [4.63002849e-01],\n",
       "        [2.99382318e-01],\n",
       "        [3.82574727e-01],\n",
       "        [4.01285208e-01],\n",
       "        [8.55131304e-01],\n",
       "        [4.35699727e-01],\n",
       "        [4.30032017e-01],\n",
       "        [8.77594726e-01],\n",
       "        [3.63721296e-01],\n",
       "        [9.69153812e-01],\n",
       "        [7.53997399e-01],\n",
       "        [6.85429335e-01],\n",
       "        [6.42231728e-02],\n",
       "        [1.11821308e-01],\n",
       "        [8.72047302e-01],\n",
       "        [9.67735287e-01],\n",
       "        [7.89197687e-01]]),\n",
       " 'first_weighted_sum': array([[80.41950872, 83.03154904, 85.66886554, ..., 83.45414323,\n",
       "         83.72532066, 81.46552287],\n",
       "        [48.0630369 , 45.22202919, 46.89864819, ..., 49.58096245,\n",
       "         45.50523064, 52.26963706],\n",
       "        [53.69723767, 52.07153516, 58.27229742, ..., 52.06051115,\n",
       "         55.04579963, 51.826146  ],\n",
       "        ...,\n",
       "        [59.2524712 , 63.70472265, 62.26100139, ..., 59.5452246 ,\n",
       "         55.38241537, 60.55808841],\n",
       "        [69.17343877, 73.30556201, 73.13495668, ..., 74.17709603,\n",
       "         67.81074406, 70.64573338],\n",
       "        [52.39727363, 56.43724056, 50.83021653, ..., 59.00965152,\n",
       "         52.19618365, 53.42109819]]),\n",
       " 'activated_hidden': array([[1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.]]),\n",
       " 'second_weighted_sum': array([[48.54039957],\n",
       "        [48.54039957],\n",
       "        [48.54039957],\n",
       "        ...,\n",
       "        [48.54039957],\n",
       "        [48.54039957],\n",
       "        [48.54039957]]),\n",
       " 'activated_output': array([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        ...,\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]]),\n",
       " 'error_output': array([[-1.],\n",
       "        [-1.],\n",
       "        [-1.],\n",
       "        ...,\n",
       "        [-1.],\n",
       "        [-1.],\n",
       "        [-1.]]),\n",
       " 'delta_output': array([[-0.],\n",
       "        [-0.],\n",
       "        [-0.],\n",
       "        ...,\n",
       "        [-0.],\n",
       "        [-0.],\n",
       "        [-0.]]),\n",
       " 'error_hidden': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " 'delta_hidden': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron.train(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9046"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(perceptron.error_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0954"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first run!\n",
    "\n",
    "np.mean(perceptron.error_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FwlRJSfBlCvy"
   },
   "source": [
    "## Stretch Goals: \n",
    "\n",
    "- Make MNIST a multiclass problem using cross entropy & soft-max\n",
    "- Implement Cross Validation model evaluation on your MNIST implementation \n",
    "- Research different [Gradient Descent Based Optimizers](https://keras.io/optimizers/)\n",
    " - [Siraj Raval the evolution of gradient descent](https://www.youtube.com/watch?v=nhqo0u1a6fw)\n",
    "- Build a housing price estimation model using a neural network. How does its accuracy compare with the regression models that we fit earlier on in class?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_432_Backprop_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "U4-S1-NLP",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
